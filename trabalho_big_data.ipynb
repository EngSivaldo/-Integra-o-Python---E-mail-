{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inoFB1CT2GB3"
      },
      "source": [
        "# Comandos para realiza√ß√£o do trabalho da mat√©ria de Big Data com uso da biblioteca PySpark.\n",
        "\n",
        "Este notebook foi projetado para guiar os alunos na realiza√ß√£o das pr√°ticas de Big Data utilizando PySpark. Certifique-se de seguir cada etapa cuidadosamente para garantir a correta execu√ß√£o das atividades.\n",
        "\n",
        "Seu trabalho come√ßar√° na c√©lula 5. Execute as 4 primeiras c√©lulas para iniciar a atividade.\n",
        "\n",
        "## <font color=red>Observa√ß√£o importante:</font>\n",
        "\n",
        "<font color=yellow>Trabalho realizado com uso da biblioteca pandas n√£o ser√° aceito!</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX7d2vvW2GB5"
      },
      "source": [
        "## Upload do arquivo `imdb-reviews-pt-br.csv` para dentro do Google Colab\n",
        "\n",
        "Aqui, voc√™ far√° o download do dataset necess√°rio para as atividades. Certifique-se de que o arquivo foi descompactado corretamente antes de prosseguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0M2F150X2GB6",
        "outputId": "aebed5d2-4194-489c-8986-613957563e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-17 20:46:16--  https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49549692 (47M) [application/zip]\n",
            "Saving to: ‚Äòimdb-reviews-pt-br.zip‚Äô\n",
            "\n",
            "imdb-reviews-pt-br. 100%[===================>]  47.25M   229MB/s    in 0.2s    \n",
            "\n",
            "2025-05-17 20:46:17 (229 MB/s) - ‚Äòimdb-reviews-pt-br.zip‚Äô saved [49549692/49549692]\n",
            "\n",
            "Archive:  imdb-reviews-pt-br.zip\n",
            "replace imdb-reviews-pt-br.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip -O imdb-reviews-pt-br.zip\n",
        "!unzip imdb-reviews-pt-br.zip\n",
        "!rm imdb-reviews-pt-br.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpRrU2rl2GB7"
      },
      "source": [
        "## Instala√ß√£o manual das depend√™ncias para uso do pyspark no Google Colab\n",
        "\n",
        "Esta etapa garante que todas as bibliotecas necess√°rias para o PySpark sejam instaladas no Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SB0ZhD4n2GB7",
        "outputId": "01f66cb5-3618-4b5b-e593-efc46648b767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyTrnJlh2GB8"
      },
      "source": [
        "## Importar, instanciar e criar a SparkSession\n",
        "\n",
        "A SparkSession √© o ponto de entrada para usar o PySpark. Certifique-se de configurar corretamente o nome do aplicativo e o master."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VEu9V5622GB8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "appName = \"PySpark Trabalho de Big Data\"\n",
        "master = \"local\"\n",
        "\n",
        "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCyRIwpS2GB9"
      },
      "source": [
        "## Criar spark dataframe do CSV utilizando o m√©todo read.csv do spark\n",
        "\n",
        "N√£o altere este c√≥digo e use o dataframe imdb_df criado aqui em todo o seu trabalho. A cria√ß√£o de um dataframe diferente deste poder√° causar erros na coluna sentiment e isso refletir√° em erros de resposta das quest√µes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6IIcJe9m2GB9"
      },
      "outputs": [],
      "source": [
        "imdb_df = spark.read.csv('imdb-reviews-pt-br.csv',\n",
        "                         header=True,\n",
        "                         quote=\"\\\"\",\n",
        "                         escape=\"\\\"\",\n",
        "                         encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cheOfRU2GB-"
      },
      "source": [
        "# Quest√£o 1\n",
        "\n",
        "Nesta quest√£o, voc√™ ir√° calcular a soma dos IDs para entradas onde o sentimento ('sentiment') √© 'neg'.\n",
        "\n",
        "### Objetivo:\n",
        "- Usar a coluna 'sentiment' como chave e somar os valores da coluna 'id'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvOORQa62GB-"
      },
      "source": [
        "## Criar fun√ß√µes de MAP:\n",
        "- Criar fun√ß√£o para mapear o \"sentiment\" como chave e o \"id\" como valor do tipo inteiro\n",
        "\n",
        "A fun√ß√£o map ir√° transformar cada linha do dataframe em uma **tupla** (chave-valor), onde:\n",
        "- Chave: coluna 'sentiment'\n",
        "- Valor: coluna 'id' convertida para inteiro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_RKA9qX2GB-",
        "outputId": "0fdb6703-0c54-4274-c368-39fc89fca4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‚Äòimdb-reviews-pt-br.csv‚Äô already there; not retrieving.\n",
            "\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "| id|             text_en|             text_pt|           sentiment|\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "|  1|Once again Mr. Co...|Mais uma vez, o S...|                 neg|\n",
            "|  2|This is an exampl...|Este √© um exemplo...|                 neg|\n",
            "|  3|First of all I ha...|\"Primeiro de tudo...| exceto Paxton e ...|\n",
            "|  4|Not even the Beat...|Nem mesmo os Beat...|                 neg|\n",
            "|  5|Brass pictures mo...|Filmes de fotos d...|                 neg|\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "‚úÖ Soma dos IDs com sentimento negativo: 247015948\n",
            "üë§ Nome: Eralice | RU: 4144099\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------\n",
        "# QUEST√ÉO 1 ‚Äì SOMA DOS IDs COM SENTIMENTO NEGATIVO\n",
        "# Nome: Eralice\n",
        "# RU: 4144099\n",
        "# ------------------------------------------\n",
        "\n",
        "# Instalar PySpark (caso ainda n√£o tenha no Colab)\n",
        "!pip install -q pyspark\n",
        "\n",
        "# Importar biblioteca\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Criar a sess√£o do Spark\n",
        "spark = SparkSession.builder.appName(\"Questao1-SomaIDsNegativos-Eralice-4144099\").getOrCreate()\n",
        "\n",
        "# Baixar automaticamente o CSV oficial do GitHub\n",
        "!wget -nc https://raw.githubusercontent.com/felipebravom/IMDb_pt-BR/master/imdb-reviews-pt-br.csv\n",
        "\n",
        "# Ler o CSV\n",
        "df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Mostrar amostra dos dados\n",
        "df.show(5)\n",
        "\n",
        "# Converter DataFrame para RDD\n",
        "rdd = df.rdd\n",
        "\n",
        "# Fun√ß√£o map1 solicitada no enunciado\n",
        "def map1(x):\n",
        "    return (x['sentiment'], int(x['id']))\n",
        "\n",
        "# Aplicar a fun√ß√£o map1\n",
        "rdd_mapeado = rdd.map(map1)\n",
        "\n",
        "# Filtrar apenas sentimentos negativos\n",
        "rdd_neg = rdd_mapeado.filter(lambda x: x[0] == 'neg')\n",
        "\n",
        "# Obter apenas os IDs e somar\n",
        "soma_ids_neg = rdd_neg.map(lambda x: x[1]).sum()\n",
        "\n",
        "# Resultado final\n",
        "print(\"‚úÖ Soma dos IDs com sentimento negativo:\", soma_ids_neg)\n",
        "print(\"üë§ Nome: Eralice | RU: 4144099\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdxB_lxD2GB-"
      },
      "source": [
        "## Cria fun√ß√µes de REDUCE:\n",
        "\n",
        "- Criar fun√ß√£o de reduce para somar os IDs por \"sentiment\".\n",
        "\n",
        "A fun√ß√£o reduce ir√° somar os valores dos IDs agrupados por chave ('sentiment')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Z16cxAEk2GB_",
        "outputId": "6ae0c7e8-633c-498d-e7ee-a28550146179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soma dos IDs por sentimento:\n",
            "neg: 247015948\n",
            "pos: 444191288\n"
          ]
        }
      ],
      "source": [
        "# Fun√ß√£o map para transformar cada linha em (sentiment, id)\n",
        "def map1(x):\n",
        "    return (x['sentiment'], int(x['id']))\n",
        "\n",
        "# Fun√ß√£o reduce para somar os IDs\n",
        "def reduce1(a, b):\n",
        "    return a + b\n",
        "\n",
        "# Aplicar o map\n",
        "rdd_mapeado = rdd.map(map1)\n",
        "\n",
        "# Filtrar para considerar s√≥ sentimentos v√°lidos: 'pos' e 'neg'\n",
        "rdd_filtrado = rdd_mapeado.filter(lambda x: x[0] in ['pos', 'neg'])\n",
        "\n",
        "# Aplicar reduceByKey para somar IDs por sentimento\n",
        "rdd_reduzido = rdd_filtrado.reduceByKey(reduce1)\n",
        "\n",
        "# Coletar o resultado\n",
        "resultado = rdd_reduzido.collect()\n",
        "\n",
        "# Imprimir resultado\n",
        "print(\"Soma dos IDs por sentimento:\")\n",
        "for sentimento, soma in resultado:\n",
        "    print(f\"{sentimento}: {soma}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWzf0w3k2GB_"
      },
      "source": [
        "## Aplica√ß√£o do map/reduce e visualiza√ß√£o do resultado\n",
        "\n",
        "Aqui, voc√™ aplicar√° as fun√ß√µes de map e reduce ao dataframe Spark para calcular os resultados. N√£o se esque√ßa de usar o m√©todo `.collect()` para visualizar os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "C0LWzhrH2GB_",
        "outputId": "bf15a5e5-0f01-4f9a-e7da-8c946b63735b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado da soma dos IDs por sentimento:\n",
            "neg: 459568555\n",
            "pos: 763600041\n",
            "\n",
            "üë§ Nome: Eralice | RU: 4144099\n"
          ]
        }
      ],
      "source": [
        "# Fun√ß√£o MAP: transforma a linha em (sentiment, id)\n",
        "def map1(x):\n",
        "    return (x['sentiment'], int(x['id']))\n",
        "\n",
        "# Fun√ß√£o REDUCE: soma dois valores\n",
        "def reduceByKey1(a, b):\n",
        "    return a + b\n",
        "\n",
        "# Aplica√ß√£o no dataframe Spark\n",
        "resultado = imdb_df.rdd.map(map1)\\\n",
        "                       .filter(lambda x: x[0] in ['pos', 'neg'])\\\n",
        "                       .reduceByKey(reduceByKey1).collect()\n",
        "\n",
        "# Imprimir o resultado com seu nome e RU\n",
        "print(\"Resultado da soma dos IDs por sentimento:\")\n",
        "for sentimento, soma in resultado:\n",
        "    print(f\"{sentimento}: {soma}\")\n",
        "\n",
        "print(\"\\nüë§ Nome: Eralice | RU: 4144099\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYY08JHZ2GB_"
      },
      "source": [
        "# Quest√£o 2:\n",
        "\n",
        "Nesta quest√£o, voc√™ ir√° calcular a diferen√ßa no n√∫mero total de palavras entre textos negativos em portugu√™s e ingl√™s.\n",
        "\n",
        "### Objetivo:\n",
        "- Contar as palavras em cada idioma (colunas 'text_pt' e 'text_en') para entradas onde o sentimento ('sentiment') √© 'neg'.\n",
        "- Subtrair o total de palavras em ingl√™s do total em portugu√™s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EroN3JMn2GB_"
      },
      "source": [
        "## Criar fun√ß√µes de MAP:\n",
        "- Criar fun√ß√£o para mapear o \"sentiment\" como chave de uma tupla principal e como valor uma outra tupla com a soma das palavras de cada idioma como valor.\n",
        "\n",
        "A fun√ß√£o map ir√° transformar cada linha do dataframe em uma tupla (chave-valor), onde:\n",
        "- Chave: coluna 'sentiment'\n",
        "- Valor: Nova tupla com:\n",
        "  - Elemento 0: soma das palavras da coluna 'text_en'\n",
        "  - Elemento 1: soma das palavras da coluna 'text_pt'\n",
        "\n",
        "OU\n",
        "- Chave: coluna 'sentiment'\n",
        "- Valor: (soma das palavras da coluna 'text_pt') - (soma das palavras da coluna 'text_en')\n",
        "  \n",
        "\n",
        "Para contar as palavras deve-se primeiro separar os textos em uma lista de palavras para ent√£o descobrir o tamanho desta lista.\n",
        "Dicas:\n",
        "\n",
        "1. Use o m√©todo .split() e n√£o .split(\" \") de string para separar as palavras em uma lista ou use a fun√ß√£o split(coluna de texto, regex) do pyspark com o regex igual √† \"[ ]+\" ou \"\\s+\"\n",
        "2. Use len() para descobrir o tamanho da lista de palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UkVNXQD12GCA",
        "outputId": "d95151cb-680e-488d-f128-ffed3199c615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento 'neg': 16029\n",
            "üë§ Nome: Eralice | RU: 4144099\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------\n",
        "# QUEST√ÉO 2 ‚Äì DIFEREN√áA DE PALAVRAS ENTRE text_pt E text_en PARA sentiment = 'neg'\n",
        "# Nome: Eralice\n",
        "# RU: 4144099\n",
        "# ------------------------------------------\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Criar sess√£o Spark (caso ainda n√£o tenha)\n",
        "spark = SparkSession.builder.appName(\"Questao2-DiferencaPalavras-Eralice-4144099\").getOrCreate()\n",
        "\n",
        "# Ler novamente o arquivo CSV (caso necess√°rio)\n",
        "df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Converter para RDD\n",
        "rdd = df.rdd\n",
        "\n",
        "# Fun√ß√£o MAP: transforma cada linha em (sentiment, (qtd_palavras_en, qtd_palavras_pt))\n",
        "def map2(x):\n",
        "    # Verifica se os textos n√£o s√£o None (para evitar erro)\n",
        "    text_en = x['text_en'] if x['text_en'] else \"\"\n",
        "    text_pt = x['text_pt'] if x['text_pt'] else \"\"\n",
        "\n",
        "    palavras_en = len(text_en.split())\n",
        "    palavras_pt = len(text_pt.split())\n",
        "\n",
        "    return (x['sentiment'], (palavras_en, palavras_pt))\n",
        "\n",
        "# Fun√ß√£o REDUCE: soma os pares de contagem\n",
        "def reduce2(a, b):\n",
        "    return (a[0] + b[0], a[1] + b[1])\n",
        "\n",
        "# Aplicar map2\n",
        "rdd_mapeado = rdd.map(map2)\n",
        "\n",
        "# Filtrar apenas sentimentos negativos\n",
        "rdd_neg = rdd_mapeado.filter(lambda x: x[0] == 'neg')\n",
        "\n",
        "# Reduzir por chave 'neg' somando as quantidades de palavras\n",
        "resultado = rdd_neg.reduceByKey(reduce2).collect()\n",
        "\n",
        "# Mostrar resultado\n",
        "for sentimento, (total_en, total_pt) in resultado:\n",
        "    diferenca = total_pt - total_en\n",
        "    print(f\"‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento '{sentimento}': {diferenca}\")\n",
        "\n",
        "print(\"üë§ Nome: Eralice | RU: 4144099\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDkH_h-S2GCA"
      },
      "source": [
        "## Cria fun√ß√µes de REDUCE:\n",
        "\n",
        "- Criar fun√ß√£o de reduce para somar o numero de palavras de cada texto portugu√™s e ingl√™s por \"sentiment\" (depender√° de como voc√™ optou por fazer sua fun√ß√£o map2).\n",
        "\n",
        "A fun√ß√£o reduce ir√° somar os valores das quantidades de palavras agrupados por chave ('sentiment')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TNSQXUrW2GCA",
        "outputId": "2ed0a1b9-48ee-42a6-be49-ec74dea8bf4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de textos negativos: 13305\n",
            "Textos em ingl√™s negativos vazios ou nulos: 0\n",
            "Textos em portugu√™s negativos vazios ou nulos: 0\n",
            "Total de palavras em ingl√™s (negativos): 2399590\n",
            "Total de palavras em portugu√™s (negativos): 2415179\n",
            "‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento 'neg': 15589\n",
            "üë§ Nome: Eralice | RU: 4144099\n",
            "\n",
            "Exemplos de textos negativos (ingl√™s e portugu√™s):\n",
            "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "|                                                                         text_en|                                                                         text_pt|\n",
            "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "|Once again Mr. Costner has dragged out a movie for far longer than necessary....|Mais uma vez, o Sr. Costner arrumou um filme por muito mais tempo do que o ne...|\n",
            "|This is an example of why the majority of action films are the same. Generic ...|Este √© um exemplo do motivo pelo qual a maioria dos filmes de a√ß√£o s√£o os mes...|\n",
            "|Not even the Beatles could write songs everyone liked, and although Walter Hi...|Nem mesmo os Beatles puderam escrever m√∫sicas que todos gostassem, e embora W...|\n",
            "|Brass pictures movies is not a fitting word for them really are somewhat bras...|Filmes de fotos de lat√£o n√£o √© uma palavra apropriada para eles, na verdade, ...|\n",
            "|This German horror film has to be one of the weirdest I have seen.I was not a...|Este filme de terror alem√£o tem que ser um dos mais estranhos que eu j√° vi. E...|\n",
            "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import split, size, col\n",
        "\n",
        "# Criar sess√£o Spark\n",
        "spark = SparkSession.builder.appName(\"ContagemPalavrasNegativas\").getOrCreate()\n",
        "\n",
        "# Ler arquivo CSV\n",
        "df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Contar quantos textos negativos existem\n",
        "qtd_neg = df.filter(df.sentiment == 'neg').count()\n",
        "print(f\"N√∫mero de textos negativos: {qtd_neg}\")\n",
        "\n",
        "# Contar textos vazios ou nulos em text_en e text_pt para negativos\n",
        "vazios_en = df.filter((col('sentiment') == 'neg') & ((col('text_en').isNull()) | (col('text_en') == ''))).count()\n",
        "vazios_pt = df.filter((col('sentiment') == 'neg') & ((col('text_pt').isNull()) | (col('text_pt') == ''))).count()\n",
        "print(f\"Textos em ingl√™s negativos vazios ou nulos: {vazios_en}\")\n",
        "print(f\"Textos em portugu√™s negativos vazios ou nulos: {vazios_pt}\")\n",
        "\n",
        "# Filtrar apenas textos negativos\n",
        "df_neg = df.filter(df.sentiment == 'neg')\n",
        "\n",
        "# Criar colunas com contagem de palavras\n",
        "df_neg = df_neg.withColumn('palavras_en', size(split(col('text_en'), ' '))) \\\n",
        "               .withColumn('palavras_pt', size(split(col('text_pt'), ' ')))\n",
        "\n",
        "# Somar total de palavras em ingl√™s e portugu√™s\n",
        "total_en = df_neg.groupBy().sum('palavras_en').collect()[0][0]\n",
        "total_pt = df_neg.groupBy().sum('palavras_pt').collect()[0][0]\n",
        "\n",
        "print(f\"Total de palavras em ingl√™s (negativos): {total_en}\")\n",
        "print(f\"Total de palavras em portugu√™s (negativos): {total_pt}\")\n",
        "\n",
        "diferenca = total_pt - total_en\n",
        "print(f\"‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento 'neg': {diferenca}\")\n",
        "\n",
        "print(\"üë§ Nome: Eralice | RU: 4144099\")\n",
        "\n",
        "# Mostrar alguns exemplos para ver os textos negativos (opcional)\n",
        "print(\"\\nExemplos de textos negativos (ingl√™s e portugu√™s):\")\n",
        "df_neg.select('text_en', 'text_pt').show(5, truncate=80)\n",
        "\n",
        "# Encerrar sess√£o Spark (opcional)\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm1Z-iPh2GCA"
      },
      "source": [
        "## Aplica√ß√£o do map/reduce e visualiza√ß√£o do resultado\n",
        "\n",
        "1. Aplicar o map/reduce no seu dataframe spark e realizar o collect() ao final\n",
        "2. Selecionar os dados referentes aos textos negativos para realizar a subtra√ß√£o.\n",
        "3. Realizar a subtra√ß√£o das contagens de palavras dos textos negativos para obter o resultado final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dlBcBjhm2GCA",
        "outputId": "cd4af836-149f-4b1b-d021-8f451e144eca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento 'neg': 16029\n",
            "üë§ Nome: Eralice | RU: 4144099\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------\n",
        "# QUEST√ÉO 2 ‚Äì DIFEREN√áA DE PALAVRAS ENTRE text_pt E text_en PARA sentiment = 'neg'\n",
        "# Nome: Eralice\n",
        "# RU: 4144099\n",
        "# ------------------------------------------\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Criar sess√£o Spark\n",
        "spark = SparkSession.builder.appName(\"Questao2-DiferencaPalavras-Eralice-4144099\").getOrCreate()\n",
        "\n",
        "# Ler o arquivo CSV com cabe√ßalho e inferindo esquema\n",
        "df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Converter DataFrame para RDD\n",
        "rdd = df.rdd\n",
        "\n",
        "# Fun√ß√£o MAP: retorna (sentiment, (qtd_palavras_en, qtd_palavras_pt))\n",
        "def map2(x):\n",
        "    text_en = x['text_en'] if x['text_en'] else \"\"\n",
        "    text_pt = x['text_pt'] if x['text_pt'] else \"\"\n",
        "    palavras_en = len(text_en.split())\n",
        "    palavras_pt = len(text_pt.split())\n",
        "    return (x['sentiment'], (palavras_en, palavras_pt))\n",
        "\n",
        "# Fun√ß√£o REDUCE: soma os pares (palavras_en, palavras_pt)\n",
        "def reduce2(a, b):\n",
        "    return (a[0] + b[0], a[1] + b[1])\n",
        "\n",
        "# Aplicar map, filtro s√≥ negativo e reduce para somar palavras\n",
        "resultado = (rdd\n",
        "             .map(map2)\n",
        "             .filter(lambda x: x[0] == 'neg')\n",
        "             .reduceByKey(reduce2)\n",
        "             .collect())\n",
        "\n",
        "# Mostrar resultado\n",
        "for sentimento, (total_en, total_pt) in resultado:\n",
        "    diferenca = total_pt - total_en\n",
        "    print(f\"‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento '{sentimento}': {diferenca}\")\n",
        "\n",
        "print(\"üë§ Nome: Eralice | RU: 4144099\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import split, size, col\n",
        "\n",
        "# Criar sess√£o Spark\n",
        "spark = SparkSession.builder.appName(\"Pratica02-DiferencaPalavras\").getOrCreate()\n",
        "\n",
        "# Ler o arquivo CSV com cabe√ßalho e esquema inferido\n",
        "df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Filtrar apenas textos negativos\n",
        "df_neg = df.filter(col('sentiment') == 'neg')A\n",
        "\n",
        "# Criar colunas para contar palavras em ingl√™s e portugu√™s\n",
        "df_neg = df_neg.withColumn('palavras_en', size(split(col('text_en'), ' '))) \\\n",
        "               .withColumn('palavras_pt', size(split(col('text_pt'), ' ')))\n",
        "\n",
        "# Somar total de palavras em ingl√™s e portugu√™s\n",
        "total_en = df_neg.groupBy().sum('palavras_en').collect()[0][0]\n",
        "total_pt = df_neg.groupBy().sum('palavras_pt').collect()[0][0]\n",
        "\n",
        "# Calcular diferen√ßa total (pt - en)\n",
        "diferenca = total_pt - total_en\n",
        "\n",
        "# Imprimir resultado final\n",
        "print(f\"‚úÖ Diferen√ßa total de palavras (pt - en) para textos negativos: {diferenca}\")\n",
        "print(\"üë§ Nome: Eralice | RU: 4144099\")\n",
        "\n",
        "# Encerrar sess√£o Spark\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "cBCCNewdNLT1",
        "outputId": "65e0d1e2-ff3f-4474-9995-6799219348a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Diferen√ßa total de palavras (pt - en) para textos negativos: 15589\n",
            "üë§ Nome: Eralice | RU: 4144099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Criar sess√£o Spark\n",
        "spark = SparkSession.builder.appName(\"ContagemNegativosRDD\").master(\"local\").getOrCreate()\n",
        "\n",
        "# Ler arquivo CSV\n",
        "imdb_df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Converter para RDD\n",
        "rdd = imdb_df.rdd\n",
        "\n",
        "# Map: para cada linha, retorna (sentiment, 1) se 'neg', sen√£o (sentiment, 0)\n",
        "mapped_rdd = rdd.map(lambda x: ('neg', 1) if x['sentiment'] == 'neg' else ('neg', 0))\n",
        "\n",
        "# Fun√ß√£o para somar os valores\n",
        "def soma(a, b):\n",
        "    return a + b\n",
        "\n",
        "# Reduzir por chave somando as ocorr√™ncias de 'neg'\n",
        "resultado = mapped_rdd.reduceByKey(soma).collect()\n",
        "\n",
        "# Mostrar resultado\n",
        "for sentimento, total in resultado:\n",
        "    print(f\"Total de textos com sentimento '{sentimento}': {total}\")\n",
        "\n",
        "# Parar Spark (opcional)\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "xKuPLQStREWG",
        "outputId": "0f0abb52-a961-4c95-cdac-d598c086e7fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de textos com sentimento 'neg': 13305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Criar sess√£o Spark\n",
        "spark = SparkSession.builder.appName(\"ContagemNegativos\").master(\"local\").getOrCreate()\n",
        "\n",
        "# Ler arquivo CSV\n",
        "imdb_df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Filtrar os textos negativos e contar\n",
        "total_negativos = imdb_df.filter(imdb_df.sentiment == 'neg').count()\n",
        "\n",
        "print(f\"Total de textos negativos: {total_negativos}\")\n",
        "\n",
        "# Parar Spark (opcional)\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "sKKA7fZwRyXA",
        "outputId": "2edde158-4faa-4e07-917a-86038a0addc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de textos negativos: 13305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import split, size, col\n",
        "\n",
        "# Criar sess√£o Spark\n",
        "spark = SparkSession.builder.appName(\"ContagemPalavrasNegativas\").getOrCreate()\n",
        "\n",
        "# Ler arquivo CSV com cabe√ßalho e inferindo o esquema\n",
        "df = spark.read.csv(\"imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Filtrar apenas os textos com sentimento negativo\n",
        "# Isso √© fundamental para atender ao enunciado que pede contar apenas palavras dos textos negativos\n",
        "df_neg = df.filter(df.sentiment == 'neg')\n",
        "\n",
        "# Contar quantos textos negativos existem\n",
        "qtd_neg = df_neg.count()\n",
        "print(f\"N√∫mero de textos negativos: {qtd_neg}\")\n",
        "\n",
        "# Contar textos vazios ou nulos em text_en e text_pt (importante para garantir que a contagem ser√° correta)\n",
        "vazios_en = df_neg.filter((col('text_en').isNull()) | (col('text_en') == '')).count()\n",
        "vazios_pt = df_neg.filter((col('text_pt').isNull()) | (col('text_pt') == '')).count()\n",
        "print(f\"Textos em ingl√™s negativos vazios ou nulos: {vazios_en}\")\n",
        "print(f\"Textos em portugu√™s negativos vazios ou nulos: {vazios_pt}\")\n",
        "\n",
        "# Criar colunas com a contagem de palavras em cada texto (em ingl√™s e portugu√™s)\n",
        "df_neg = df_neg.withColumn('palavras_en', size(split(col('text_en'), ' '))) \\\n",
        "               .withColumn('palavras_pt', size(split(col('text_pt'), ' ')))\n",
        "\n",
        "# Somar total de palavras em ingl√™s e portugu√™s nos textos negativos\n",
        "total_en = df_neg.groupBy().sum('palavras_en').collect()[0][0]\n",
        "total_pt = df_neg.groupBy().sum('palavras_pt').collect()[0][0]\n",
        "\n",
        "print(f\"Total de palavras em ingl√™s (negativos): {total_en}\")\n",
        "print(f\"Total de palavras em portugu√™s (negativos): {total_pt}\")\n",
        "\n",
        "# Calcular a diferen√ßa entre total de palavras em portugu√™s e ingl√™s\n",
        "diferenca = total_pt - total_en\n",
        "print(f\"‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento 'neg': {diferenca}\")\n",
        "\n",
        "print(\"üë§ Nome: Eralice | RU: 4144099\")\n",
        "\n",
        "# Exibir exemplos dos textos negativos (opcional, para valida√ß√£o visual)\n",
        "print(\"\\nExemplos de textos negativos (ingl√™s e portugu√™s):\")\n",
        "df_neg.select('text_en', 'text_pt').show(5, truncate=80)\n",
        "\n",
        "# Encerrar sess√£o Spark (boa pr√°tica)\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "uPtGfyXxTMXV",
        "outputId": "fb530ec0-af7e-46fb-f552-e98813071fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N√∫mero de textos negativos: 13305\n",
            "Textos em ingl√™s negativos vazios ou nulos: 0\n",
            "Textos em portugu√™s negativos vazios ou nulos: 0\n",
            "Total de palavras em ingl√™s (negativos): 2399590\n",
            "Total de palavras em portugu√™s (negativos): 2415179\n",
            "‚úÖ Diferen√ßa total de palavras (pt - en) para sentimento 'neg': 15589\n",
            "üë§ Nome: Eralice | RU: 4144099\n",
            "\n",
            "Exemplos de textos negativos (ingl√™s e portugu√™s):\n",
            "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "|                                                                         text_en|                                                                         text_pt|\n",
            "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "|Once again Mr. Costner has dragged out a movie for far longer than necessary....|Mais uma vez, o Sr. Costner arrumou um filme por muito mais tempo do que o ne...|\n",
            "|This is an example of why the majority of action films are the same. Generic ...|Este √© um exemplo do motivo pelo qual a maioria dos filmes de a√ß√£o s√£o os mes...|\n",
            "|Not even the Beatles could write songs everyone liked, and although Walter Hi...|Nem mesmo os Beatles puderam escrever m√∫sicas que todos gostassem, e embora W...|\n",
            "|Brass pictures movies is not a fitting word for them really are somewhat bras...|Filmes de fotos de lat√£o n√£o √© uma palavra apropriada para eles, na verdade, ...|\n",
            "|This German horror film has to be one of the weirdest I have seen.I was not a...|Este filme de terror alem√£o tem que ser um dos mais estranhos que eu j√° vi. E...|\n",
            "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TC1EPSqwTIGW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}